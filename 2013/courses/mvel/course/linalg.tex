\documentclass[a4paper]{article}
\usepackage[simple]{dmvn}
\title{Введение в линейную алгебру}
\author{Сказочник: Миша Вельтищев}
\date{Физическое отделение ЛЭШ, 1 цикл, 2013 г.}

\begin{document}
\maketitle

\section*{Введение}

Далее мы будем пользоваться некоторыми стандартными обозначениями.
\begin{items}{-2}
\item $\R$\т множество вещественных (действительных чисел)
\item $\N$\т множество натуральных чисел ($\N = \hc{1,2,3\etc}$)
\item $f\cln A\ra B$\т отображение (функция) из множества $A$ в множество $B$
\end{items}


Далее по тексту СЛУ означает <<система линейных уравнений>>, то есть система вида
$$
\case{
a_{11}x_1 + a_{12}x_2 \spl a_{1n}x_n &= b_1\\
a_{21}x_1 + a_{22}x_2 \spl a_{2n}x_n &= b_2\\
&\dots\\
a_{m1}x_1 + a_{m2}x_2 \spl a_{mn}x_n &= b_m,\\
}
$$
где $x_i$\т неизвестные, а $a_{ij}$\т фиксированные (вещественные) коэффициенты, то есть $a_{ij} \in \R$.

В случае, если все $b_i = 0$, то такая СЛУ называется \emph{однородной} (ОСЛУ).


\emph{Матрица системы}\т это матрица, состоящая из коэффициентов $a_{ij}$. При решении методом Гаусса рассматривают также \emph{расширенную матрицу системы},
которая состоит из обычной матрицы системы и вдобавок к ней приклеен ещё один столбец свободных членов, вот так
$$
\rbmat{
a_{11}& a_{12} & \dots & a_{1n} & b_1\\
a_{21}& a_{22} & \dots & a_{2n} & b_2\\
\hdotsfor{5}\\
a_{m1}& a_{m2} & \dots & a_{mn} & b_m\\
}
$$
(Естественно, если мы рассматриваем ОСЛУ, то будем писать только обычную матрицу системы (нерасширенную), чтобы не таскать за собой столбец нулей.


\section{Метод Гаусса решения систем линейных уравнений}

Сам метод Гаусса был достаточно хорошо и подробно изложен, если есть вопросы\т задавайте в частном порядке.

Преобразования, которые проводятся в методе Гаусса, называются \emph{элементарными преобразованиями} (напомним, что они
бывают трёх типов\т перестановка строк, умножение строки на ненулевое число и прибавление к строке другой строки, умноженной на число).

Как следует из метода Гаусса, матрица системы приводится к ступенчатому виду,
а именно
$$\rbmat{\dots & a_{1k_1} & &\\
\hdotsfor{2} & a_{2k_2} & & &\\
\hdotsfor{3} & a_{3k_3} & & & \\
\hdotsfor{7}\\
\hdotsfor{5} & a_{rk_r} & \dots\\}
$$
то есть в первых $r$ строках первыми ненулевыми элементами являются элементы $a_{ik_i}$, а над этой <<лестницей>> может стоять что угодно.
Остальные $m-r$ строк матрицы состоят сплошь из нулей.

Неизвестные, которые соответствуют столбцам $k_i$, называются связанными, а остальные неизвестные\т свободными.
Как легко видеть, свободные неизвестные могут принимать любые значения, а связанные\т выражаются через них
с какими\д то коэффициентами.

\begin{ex}
Рассмотрим ОСЛУ с матрицей
$$
\rbmat{
1&0&-2\\
0&1&3}
$$
Из вида матрицы сразу ясно, что $x_3$\т свободная переменная, $x_2 = -3x_3$ и $x_1 = 2x_3$.
\end{ex}

Понятное дело, что если система однородная, то у неё всегда есть тривиальное решение, а именно\т все $x_i = 0$.
Однако в некоторых случаях про её решения можно сказать больше:

\begin{stm}
Рассмотрим ОСЛУ, у которой количество неизвестных $n$ строго больше, чем количество уравнений $m$.
Тогда существует решение этой системы $(x_1\sco x_n) \ne 0$.
\end{stm}

\begin{proof}
Достаточно придать любой свободной переменной ненулевое значение.
\end{proof}

\begin{note}
Совершенно не обязательно при этом, что все компоненты вектора решения будут отличны от нуля. Но важно, чтобы была ненулевой
хотя бы одна из них.
\end{note}

\begin{ex}
Рассмотрев систему из предыдущего примера, достаточно взять, скажем, $x_3 = 1$ (да и вообще, любое $x_3 \ne 0$),
и мы получим ненулевое частное решение $(2,-3,1)$.
\end{ex}

\section{Векторные пространства}

\begin{df}
\emph{Векторным пространством} (над полем вещественных чисел $\R$)
называется множество $V$ с операциями $+$ (сложение векторов)
и $\cdot$ (умножения на вещественные числа), удовлетворяющими следующим свойствам:\\
1) $a + b= b+a$ для всех $a,b \in V$ (коммутативность сложения);\\
2) $(a + b)+c= a+(b+c)$ для всех $a,b,c \in V$ (ассоциативность сложения);\\
3) существует такой элемент $0 \in V$, что для всех $a + 0 = a$;\\
4) для каждого $a \in V$ существует такой элемент $a' \in V$, что для всех $a + a' = 0$;\\
5) $\la\cdot(a+b) = \la\cdot a + \la\cdot b$ для всех $\la \in \R$ и $a,b \in V$ (векторная дистрибутивность);\\
6) $(\la+\mu)\cdot a = \la\cdot a + \mu\cdot a$ для всех $\la,\mu \in \R$ и $a \in V$ (скалярная дистрибутивность);\\
7) $\la(\mu a) = (\la \mu)a$ для всех $\la, \mu \in \R$ и $a \in V$;\\
8) $1 \cdot a = a$ для всех $a \in V$.

Элементы множества $V$ называются \emph{векторами}.
\end{df}

Вещественные числа мы часто будем в данном контексте называть \emph{скалярами}.

\begin{ex}
Рассмотрим множество пар вещественных чисел $V := \hc{(x,y) \vl x,y\in \R}$.
Определим операции сложения и умножения на парах естественным образом, то есть
$(x_1,y_1) + (x_2,y_2) = (x_1+x_2, y_1+y_2)$ и умножения на скаляр $\la\in \R$
по правилу $\la\cdot (x,y) = (\la x, \la y)$. Ясно, что такое множество будет векторным пространством.

Аналогично можно рассмотреть не пары, а тройки вещественных чисел, и вообще $n$\д ки чисел, то есть
рассмотреть множество $V := \hc{(x_1\sco x_n) \vl x_i \in \R}$, с аналогично определёнными
операциями сложения и умножения.
\end{ex}

Введём одно соглашение. Векторы часто будем обозначать маленькими латинскими буквами,
а коэффициенты\т греческими ($\la, \mu\etc$).

Пусть $V$\т векторное пространство (сохраним это обозначение в этой главе).

\begin{df}
Пусть $v_1\sco v_k \in V$, а $\la_1\sco \la_k \in \R$. Тогда вектор
$v = \la_1v_1\spl \la_kv_k$ называется \emph{линейной комбинацией} векторов $v_1\sco v_k$ с коэффициентами
$\la_1\sco \la_k$.

Линейная комбинация называется тривиальной, если все $\la_i$ равны нулю.
\end{df}

\begin{df}
Векторы $v_1\sco v_k$ называются \emph{линейно зависимыми}, если существуют такие коэффициенты
$\la_1\sco \la_k$ (причём не все равные нулю одновременно), что $\la_1v_1\spl \la_kv_k = 0 \in V$.
\end{df}

\begin{stm}
Система векторов линейно зависима тогда и только тогда, когда хотя бы один из векторов линейно выражается через остальные.
\end{stm}
\begin{problem}
Доказать это утверждение.
\end{problem}

\begin{problem}
Приведите пример, показывающий, что если в предыдущем утверждении слова <<хотя бы один>> заменить на <<любой>>,
то оно перестаёт быть верным.
\end{problem}

\begin{stm}
Пусть $A$\т матрица, а $\hc{v_1\sco v_n}$\т векторы, составляющие её столбцы. Пусть $A'$\т матрица, полученная из $A$
элементарным преобразованием, и $\hc{v_i'}$\т её векторы\д столбцы. Тогда если $\la_1v_1 \spl \la_n v_n = 0$,
то и $\la_1 v_1' \spl \la_n v_n' = 0$ (а если $\ne 0$, то и во втором случае\т $\ne 0$).
\end{stm}
\begin{proof}
Запишем исходное условие в координатах:
$$
\case{
\la_1 v_{11} + \la_2 v_{12} \spl \la_n v_{1n} &= b_1,\\
\la_1 v_{21} + \la_2 v_{22} \spl \la_n v_{2n} &= b_2,\\
&\dots\\
\la_1 v_{m1} + \la_2 v_{m2} \spl \la_n v_{mn} &= b_m,
}
$$
(здесь $v_i = (v_{1i}\sco v_{mi})$, записанный в виде столбца матрицы).

Пусть сначала все $b_i = 0$. Рассмотрим все три случая элементарных преобразований.

1) перестановка строк: легко видеть, что она соответствует перестановке соответствующих равенств (поэтому ничего не поменяется, и нули в правой части сохранятся).

2) умножение строки на ненулевое число: проблем опять-таки нет\т все равенства останутся без изменений, кроме одного, которое будет домножено на это ненулевое число
(но от этого равенство нулю не испортится)

3) сложение двух строк матрицы: в этом случае переход от $\hc{v_i}$ к $\hc{v_i'}$ соответствует просто сложению равенств.

Совершенно аналогично можно показать, что если хотя бы одно из $b_i$ не равно нулю, то после преобразований хотя бы одно из $b_i$ останется ненулевым (упражнение).
\end{proof}

\begin{lemma}[Основная лемма о линейной зависимости]
Пусть векторы $v_1\sco v_s$ линейно выражаются через векторы $w_1\sco w_t$, причём $s > t$. Тогда векторы $v_1\sco v_s$ линейно зависимы.
\end{lemma}
\begin{proof}
Напишем линейное выражение для векторов $v_i$:
$$
\case{
v_1 &= \la_{11}w_1 \spl \la_{1t} w_t,\\
v_2 &= \la_{21}w_1 \spl \la_{2t} w_t,\\
&\dots\\
v_s &= \la_{s1}w_1 \spl \la_{st} w_t.}
$$
Мы хотим доказать, что существует такой набор коэффициентов $a_1\sco a_s$, что $a_1v_1\spl a_s v_s = 0$.
Найдём мы его следующим образом. Рассмотрим ОСЛУ с матрицей
$$
\rbmat{
\la_{11} & \la_{21} & \dots & \la_{s1}\\
\la_{12} & \la_{22} & \dots & \la_{s2}\\
\hdotsfor{4}\\
\la_{1t} & \la_{2t} & \dots & \la_{st}}.
$$
В этой системе $s$ неизвестных и $x_1\sco x_s$ и $t$ уравнений. Поэтому такая система обязательно имеет ненулевое решение $(a_1\sco a_s)$.
А теперь осталось заметить, что этот набор коэффициентов подходит.

Действительно, имеем систему равенств
$$
\case{
\la_{11}a_1 + \la_{21}a_2 \spl \la_{s1}a_s &= 0,\\
\la_{12}a_1 + \la_{22}a_2 \spl \la_{s2}a_s &= 0,\\
&\dots\\
\la_{1t}a_1 + \la_{2t}a_2 \spl \la_{st}a_s &= 0}
$$

Проверим, например, что 1\д я координата вектора $a_1v_1\spl a_s v_s$ равна нулю. В самом деле,
\begin{multline*}
a_1v_{11}\spl a_s v_{s1} = w_{11}\cdot (\la_{11}a_1 + \la_{21}a_2 \spl \la_{s1}a_s) +\\+
w_{21}\cdot (\la_{12}a_1 + \la_{22}a_2 \spl \la_{s2}a_s) \spl
w_{t1} \cdot (\la_{1t}a_1 + \la_{2t}a_2 \spl \la_{st}a_s) = 0,
\end{multline*}
потому что в каждом выражении в скобках стоит нуль.

Аналогично проверяется равенство нулю всех остальных координат.

То же самое доказательство проще было бы записать в терминах матричного умножения, и мы сделаем это чуть позже.
\end{proof}

\begin{df}
\emph{Ранг} системы векторов\т максимальное количество линейно независимых векторов в этой системе.
\end{df}

Заметим, что это определение до поры до времени не вполне корректно. Нужно обосновать,
почему количество линейно\д независимых векторов одно и то же, независимо от того, какие именно векторы
мы будем выбирать. Максимальность определяется следующим образом: максимальная линейно\д независимая подсистема\т это такая подсистема,
к которой нельзя добавить ни одного вектора из системы, чтобы она осталась линейно\д независимой.

\begin{proof}
В самом деле, пусть $v_1\sco v_k$ и $w_1 \sco w_m$\т две такие системы, причём к каждой из них добавить уже ничего нельзя,
и они линейно независимы. Заметим, что через каждую из этих систем линейно выражается любой другой вектор $v$ системы.
Действительно, если $\la_0 v + \la_1v_1\spl \la_k v_k = 0$, то обязательно $\la_0 \ne 0$, иначе мы получим нетривиальную линейную комбинацию
линейно независимых векторов $v_1 \sco v_k$, равную нулю. Стало быть, $v = -\hr{\frac{\la_1}{\la_0}v_1\spl \frac{\la_k}{\la_0} v_k}$,
то есть $v$ выражается через $v_1\sco v_k$.

В частности, через $v_1\sco v_k$ выражаются векторы $w_1\sco w_m$. Совершенно аналогично показывается, что через векторы
$w_1\sco w_m$ выражаются векторы $v_1\sco v_m$. Теперь, если предположить, что $m \ne k$, то, применяя основную лемму о линейной зависимости,
сразу получаем противоречие, потому что оба набора векторов были линейно независимыми.
\end{proof}

\begin{stm}
При проведении элементарных преобразований над строками матрицы ранг системы строк не меняется.
\end{stm}
\begin{proof}
Легко видеть, что при проведении любого элементарного преобразования можно линейно выразить старые строки матрицы через новые (проделайте это самостоятельно!),
и наоборот (потому что элементарные преобразования обратимы).
Проводя рассуждение, аналогичное предыдущему, получаем, что ранги исходной системы строк и той, которая получилась после преобразования, должны совпадать.
\end{proof}

\begin{df}
\emph{Базис векторного пространства}\т максимальная линейно  независимая подсистема векторов этого пространства.
\end{df}

\section{Лирическое отступление про операции с матрицами}

Как выяснилось, матрицы\т это не только удобный способ для записи систем линейных уравнений. С ними можно проводить различные операции
(они нам понадобятся для того, чтобы сократить и упростить запись).

Пространство матриц размера $m \times n$ мы будем обозначать $\Mat_{m \times n}$ (обозначение не ахти какое стандартное, в книгах можно найти и другие,
но такое тоже встречается).

Для матриц (которые обычно обозначаются латинскими заглавными буквами $A, B, C\dots$), иногда используется обозначение вида $(a_{ij})$ (чтобы показать, как
обозначены матричные элементы и какие там бегают индексы).

Пусть $A, B \in \Mat_{m\times n}$, а $\la \in \R$.

1) Сложение матриц. Пусть $A = (a_{ij})$, $B = (b_{ij})$, тогда суммой матриц $A+B$ называется матрица $C = (c_{ij})$, для которой
$c_{ij} := a_{ij} + b_{ij}$.

\begin{note}
Складывать матрицы разных размеров между собой нельзя! Кроме того, надо помнить, что, вообще говоря, $\Mat_{m \times n}$ и $\Mat_{n \times m}$\т разные вещи!
\end{note}

2) Умножение матрицы на скаляр $\la \in \R$: $\la A = (c_{ij})$, где $c_{ij} := \la a_{ij}$ (иначе говоря, при умножении матрицы на число
каждый её элемент умножается на это число). Здесь $\la$ может быть произвольным числом (в том числе~$0$).

\begin{stm}
Пространство матриц $\Mat_{m \times n}$ является векторным пространством.
\end{stm}
\begin{proof}
Доказывать нечего, поскольку можно все элементы матрицы выписать в одну строку длины $mn$, и тогда сложение матриц и умножение их на числа сведётся
к сложению и умножению на числа векторов\д строк длины~$mn$, то есть, грубо говоря, \emph{как векторные пространства}, множества
$\Mat_{m\times n}$ и $\R^{mn}$ одинаковы.
\end{proof}


Значительно более интересной операцией является \emph{умножение матрицы на матрицу}. Пусть $A = (a_{ij}) \bw\in \Mat_{m \times n}$,
а $B = (b_{jk}) \bw\in \Mat_{n \times p}$. Тогда произведением матриц $A$ и $B$ (именно в таком порядке!) называется матрица $C = (c_{ij}) \bw\in \Mat_{m\times p}$,
элементы которой определяются следующим образом:
$$c_{ik} = \suml{j=1}{n} a_{ij} b_{jk} = a_{i1}b_{1k} \spl a_{in}b_{nk}.$$
Схематически перемножение можно изобразить так:
$$
\rbmat{
\phantom{aa} & \phantom{aa} & & \\
\hdotsfor{2} & a_{ij} & \dots \\
 &  & & \\}
\rbmat{
 &  & \vdots & \\
 &  & \vdots & \\
 &  & b_{jk} &  \\
 &  & \vdots & \\}
$$
При умножении мы бежим по строке и столбцу, выделенным пунктиром.

\begin{note}
Если размеры матриц не согласованы, то есть если количество столбцов первой матрицы не равно количеству строк второй матрицы, то такие матрицы перемножать нельзя.
Кроме того, вполне может быть так, что можно умножить $A$ на $B$ (то есть произведение $AB$ существует), но в обратном порядке умножить нельзя (то есть произведение $BA$
не определено из\д за несогласованности размеров).
\end{note}

\begin{problem}
Докажите, что умножение матриц обладает дистрибутивностью:\\
1) $A(B+C) = AB + AC$,\\
2) $(B+C)A = AB + CA$.
\end{problem}
\begin{note}
В предыдущей задаче можно доказывать только одно из свойств\т второе доказывается аналогично,
но необходимо понимать, что формально надо проверять оба, ибо одно из другого не следует.
\end{problem}

\begin{problem}
Докажите, что умножение матриц ассоциативно: $(AB)C = A(BC)$.
\end{problem}


\begin{problem}
Приведите пример, показывающий, что умножение матриц, вообще говоря,
не коммутативно, то есть даже если существуют оба произведения $AB$ и $BA$, то не обязательно $AB = BA$.
\end{problem}

\begin{problem}
Рассмотрим пространство квадратных матриц размера $n\times n$. Найти все такие матрицы $X$, которые коммутируют с любой другой матрицей того же размера,
то есть найти все такие $X$, что для любой $A \in \Mat_{n\times n}$ выполнено $AX = XA$.
\end{problem}


\section{Изоморфизмы векторных пространств}

Пусть $V, W$\т (конечномерные) векторные пространства.

\begin{df}
Отображение $f\cln V \ra W$ называется изоморфизмом векторных пространств, если $f$ взаимно\д однозначно и выполнены два свойства:\\
1) $f(x + y) = f(x) + f(y)$ для всех $x, y \in V$;\\
2) $f(\la x) = \la f(x)$ для всех $\la \in \R$ и $x \in V$.
\end{df}

\begin{problem}
Докажите, что если $f$\т изоморфизм, то $f(0) = 0$.
\end{problem}

\begin{problem}
Покажите, что утверждение предыдущей задачи остаётся верным даже в том случае, если не требовать от отображения $f$ биективности.
\end{problem}


\begin{stm}
Если $f\cln V \ra W$\т изоморфизм, то $f$ переводит базис пространства $V$ в базис пространства $W$.
\end{stm}
\begin{proof}
Пусть $v_1\sco v_n$\т базис пространства $V$. Проверим, что  $f(v_1)\sco  f(v_n)$\т базис пространства $W$.
Сначала проверим линейную независимость этих векторов. Допустим, что
$\la_1 f(v_1) \spl \la_n f(v_n) = 0$.
По свойствам изоморфизма отсюда следует, что
$f(\la_1v_1 \spl \la_n v_n ) = 0$. Но мы знаем (см.~задачи), что $f(0) = 0$, и потому (в силу инъективности $f$) $\la_1 v_1 \spl \la_n v_n = 0$.
Отсюда уже следует, что все $\la_i = 0$, потому что $v_1\sco v_n$\т базис. Таким образом, линейная независимость проверена.

Теперь докажем, что через них всё выражается. Для этого рассмотрим произвольный вектор $y \in W$. Поскольку $f$\т изоморфизм, то для
$y$ существует и притом единственный элемент $x \in V$, что $f(x) = y$ (более точно, это следствие сюръективности $f$). Разложим $x$ по базису:
$x = \la_1 v_1\spl \la_n v_n$. Отсюда следует, что $y = f(x) = f(\la_1 v_1\spl \la_n v_n) = \la_1 f(v_1) \spl \la_n f(v_n)$.
\end{proof}
\begin{imp}
Размерности изоморфных векторных пространств равны.
\end{imp}

\begin{stm}
Пусть $V, W$\т конечномерные векторные пространства, размерности которых равны. Тогда между ними существует изоморфизм.
\end{stm}
\begin{proof}
Зафиксируем базисы пространств $V$ и $W$\т $\hc{v_1\sco v_n}$ и $\hc{w_1\sco w_n}$ соответственно.
Рассмотрим произвольный вектор $v \in V$, он разлагается по базису пространства $V$: $v = \la_1 v_1 \spl \la_n v_n$.
Определим отображение $f\cln V \ra W$ следующим образом: $f(v) := \la_1 w_1 \spl \la_n w_n$ (то есть вектору $v$ ставится в соответствие
вектор с такими же координатами, но только в другом базисе).
\end{proof}

\begin{problem}
Завершить доказательство утверждения, то есть проверить, что $f$\т действительно изоморфизм.
\end{problem}

\section{Дополнительно возникшие задачи}

\begin{problem}
Доказать тождество Якоби для векторных произведений (выдана двум девушкам).
\end{problem}

\begin{problem}
Рассмотрим пространство $\R^\bes = \hc{(x_1\sco x_n\etc) \vl x_i \in \R}$ строк со счётным количеством координат (операции над ними аналогичны
операциям в пространстве $\R^n$). Рассмотрим в нём набор векторов
$e_i = (0\sco 0, \underset{i}{1}, 0\etc)$. Показать, что этот набор не является базисом.
\end{problem}


\section{Перестановки. Симметрическая группа $\Sb_n$}

\begin{df}
Рассмотрим конечное множество $M = \hc{1\sco n}$. Произвольное биективное отображение $\si\cln M \ra M$ называется \emph{перестановкой}
(или подстановкой\т это синонимы). Множество всех подстановок обозначается $\Sb_n$.
\end{df}

Подстановки можно задавать табличками такого вида: $\rbmat{1&2&3&\dots&n\\\si(1)&\si(2)&\si(3)&\dots&\si(n)}$. При этом в нижней строке должны встретиться
все числа от $1$ до $n$, причём ровно по одному разу.

\begin{ex}
Перестановка $5$ элементов: $\rbmat{1&2&3&4&5\\3&2&5&1&4}$.
\end{ex}

На множестве перестановок можно ввести операцию <<умножения>>, которая является обычной композицией отображений $\circ$.
Именно, $(\si_2\circ \si_1)(x) := \si_2(\si_1(x))$. Результатом такого умножения является, разумеется, тоже перестановка.

\begin{ex}
Пусть $\si_1 = \rbmat{1&2&3&4&5\\3&2&5&1&4}$, $\si_2 = \rbmat{1&2&3&4&5\\2&1&3&5&4}$.
Тогда $\si_2\circ\si_1 = \rbmat{1&2&3&4&5\\3&1&4&1&4}$
\end{ex}

\begin{problem}
Операция $\circ$ для произвольных отображений ассоциативна, то есть $(\ph\circ \psi)\circ \tau = \ph\circ (\psi\circ \tau)$,
где $\tau \cln A\ra B$, $\psi\cln B \ra C$, $\ph\cln C \ra D$.
\end{problem}

\section{Определители квадратных матриц}

\begin{df}
Пусть задана матрица $A = (a_{ij}) \in \Mat_{n\times n}$. Определителем матрицы называется число
$$\det A = \hm{A} := \sums{\si \in \Sb_n} (\sgn \si \cdot a_{1\si(1)}\cdot a_{2\si(2)}\sd a_{n\si(n)}).$$
\end{df}

Как видно из этого определения, в сумме содержится $n!$ слагаемых, и потому непосредственное вычисление определителя при больших $n$ (по определению) довольно трудоёмко.
Однако мы увидим, что в конкретных числовых задачах можно вычислять определитель с помощью слегка модифицированного алгоритма Гаусса.

На определитель можно смотреть не только как на отображение $\det\cln \Mat_{n\times n}\ra \R$, но и как на отображение
$$\det\cln \ub{\R^n\st\R^n}_n\ra \R,$$
если рассматривать матрицу как $n$ векторов\д строк $v_1 = (a_{11}\sco a_{1n}),$ \dots, $v_n = (a_{n1}\sco a_{nn})$.

Для дальнейшего нам потребуется одно важное понятие.

\begin{df}
Пусть $V, W$\т векторные пространства. Отображение $L\cln V\ra W$ называется линейным, если $L(x+y) = L(x) + L(y)$ и $L(\la x) = \la L(x)$
для всех $x,y \in V$ и $\la \in \R$.
\end{df}

Это определение допускает естественное обобщение:
\begin{df}
Пусть $V, W$\т векторные пространства. Отображение
$$L\cln \ub{V\st V}_n\ra W$$
называется \emph{полилинейным}, если
$$L(v_1\sco v_i+ w_i\sco v_n) = L(v_1\sco v_i \sco v_n) + L(v_1\sco w_i \sco v_n)$$
и
$$L(v_1\sco \la v_i\sco v_n) = \la L(v_1\sco v_i\sco v_n)$$
для всех $v_1\sco v_n, w_i \in V$ и $\la \in \R$.
\end{df}

\pt1 Определитель является полилинейным отображением.
\begin{proof}
Докажем только аддитивность, а однородность (умножение на $\la$) оставим для читателя. Пусть $i$\д я строка матрицы является суммой двух векторов, то есть $a_{ij} = b_{ij} + c_{ij}$ при
$j = 1\sco n$ и фиксированном $i$. Тогда, как легко видеть,
\begin{multline*}
\det A = \sums{\si \in \Sb_n} \sgn \si a_{1\si(1)}\dots (b_{i\si(i)} + c_{i\si(i)})\dots a_{n\si(n)}=\\=
\sums{\si \in \Sb_n} \sgn \si a_{1\si(1)}\dots b_{i\si(i)}\dots a_{n\si(n)} +
\sums{\si \in \Sb_n} \sgn \si a_{1\si(1)}\dots c_{i\si(i)}\dots a_{n\si(n)} = \det B + \det C,
\end{multline*}
где $B$ и $C$\т матрицы, которые получаются из матрицы $A$ заменой $i$\д строки на слагаемые, составляющие её в матрице $A$.
\end{proof}

\begin{df}
Отображение называется \emph{кососимметрическим}, если оно меняет знак при смене любых двух аргументов:
$f(\dots, x\sco y\etc) = - f(\dots,y\sco x\etc)$.
\end{df}

\pt2 Определитель является кососимметрической функцией своих аргументов.
\begin{proof}
В самом деле, переставим две строки в определителе $\hm{A}$, получим определитель $\hm{A'}$
и посчитаем его (точнее, посмотрим, чем он отличается от исходного определения).
$$\hm{A'} = \sums{\si \in \Sb_n} \sgn \si a_{1\si(1)} a_{2\si(2)} \dots a_{j\si(i)}\dots a_{i\si(j)}\dots a_{n\si(n)}.$$
Пусть $\tau = (ij)$, то есть это транспозиция, переставляющая элементы $i$ и $j$. Применим такой трюк:
заменим суммирование по $\si$ на суммирование по всем $\si \tau$. При этом слагаемые останутся теми же самыми, потому что множества подстановок вида $\hc{\si\tau}$
и $\hc{\si}$ совпадают, но знаки в каждом слагаемом поменяются, потому что $\sgn \si\tau = -\sgn \si$. Следовательно,
$$-\hm{A'} = \sums{\si \in \Sb_n} \sgn \si a_{1\si\tau(1)} a_{2\si\tau(2)} \dots a_{j\si\tau(i)}\dots a_{i\si\tau(j)}\dots a_{n\si\tau(n)}.$$
Осталось заметить, что $\tau$ не действует ни на какие элементы, кроме $i$ и $j$, поэтому последнее равенство можно переписать в следующем виде:
$$-\hm{A'} = \sums{\si \in \Sb_n} \sgn \si a_{1\si(1)} a_{2\si(2)} \dots a_{j\si(j)}\dots a_{i\si(i)}\dots a_{n\si(n)}.$$
Последнее выражение с точностью до порядка множителей совпадает с выражением для определителя матрицы $A$. Таким образом, $\hm{A'} = -\hm{A}$, что
и требовалось доказать.
\end{proof}

\pt3 Если в матрице две строки одинаковы, то определитель этой матрицы равен нулю.
\begin{proof}
В самом деле, пусть матрица имеет две одинаковые строки. Переставим их местами. Тогда, с одной стороны, определитель должен поменять знак (по свойству \pt2),
а с другой стороны, матрица не поменяется (потому что строки одинаковы). Следовательно, $\hm{A} = -\hm{A}$, откуда $\hm{A} = 0$.
\end{proof}
\begin{note}
Это доказательство не годится в том случае, если поле, над которым рассматривается матрица, имеет характеристику $2$ (мы рассматривали только векторные пространства
над $\R$, которое имеет характеристику нуль). Однако эту трудность легко обойти.
\end{note}

\pt4 Пусть $a_1\sco a_n$\т вектора\д строки матрицы $A$. Тогда определитель матрицы $A'$ со строками $a_1\sco a_i+\la a_j\sco a_j \sco a_n$ равен определителю
исходной матрицы $A$.
\begin{proof}
В самом деле,
\begin{multline*}
\det A' = \det (a_1\sco a_i+\la a_j\sco a_j \sco a_n) =\\=
\det(a_1\sco a_i\sco a_j \sco a_n) + \la\det(a_1\sco a_j\sco a_j \sco a_n) = \det A + \la \cdot 0,
\end{multline*}
потому что вторая матрица имеет две одинаковые строки.
\end{proof}


\section{Линейные отображения и билинейные функции}



\end{document}
